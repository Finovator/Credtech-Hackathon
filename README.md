# Explainable Credit Intelligence Platform

A web-based platform that predicts **creditworthiness** of companies and provides **explainable AI (XAI) insights** for decision transparency.  
This project was developed for the Hackathon to showcase Responsible AI in finance.

---

## ğŸš€ Features
- **Credit Scoring**: Predicts probability of default or approval using ML models.  
- **Explainability**: SHAP-based feature importance visualization for model transparency.  
- **Interactive UI**: Built with Streamlit, lightweight and easy to run locally.  
- **Frontend Styling**: Custom `style.css` for modern look and usability.  
- **Transparency**: Displays prediction score (KPI) and detailed explanations below.  

---

## ğŸ› ï¸ Tech Stack
- **Frontend**: Streamlit + CSS styling  
- **Backend**: Python, Scikit-learn models  
- **Explainability**: SHAP (SHapley Additive exPlanations)  
- **Other Tools**: Pandas, Numpy, Matplotlib, Plotly, Joblib  

---

## âš¡ Local Setup Instructions

Run the following commands step by step:

```bash
# 1. Clone the repository
git clone <your-repo-link>
cd <repo-folder>

# 2. (Optional) Create virtual environment
python -m venv venv
source venv/bin/activate    # Mac/Linux
venv\Scripts\activate       # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start the app
streamlit run app.py

```

---

## ğŸ—ï¸ System Architecture

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Raw Data  â”‚
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Preprocessing   â”‚ â†’ Handling missing values, normalization
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ML Models       â”‚ â†’ Logistic Regression, Random Forest, XGBoost
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Explainability  â”‚ â†’ SHAP values + text reasoning
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Visualization   â”‚ â†’ Streamlit + Plotly
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

## âš–ï¸ Key Tradeoffs

Accuracy vs. Interpretability: Deep models could boost accuracy but reduce transparency; SHAP balances this by explaining predictions.

Performance vs. Usability: Chose Streamlit for rapid prototyping over heavier web frameworks.

Data Generality vs. Specificity: Model trained on structured company features; could be more generalizable with larger datasets.

---

## ğŸ“Š Model Comparisons
1.Logistic Regression
Accuracy: 76%
AUC: 0.71
Interpretability: High (easy to explain)
Deployment Readiness: âœ… Easy to deploy

2.Random Forest
Accuracy: 83%
AUC: 0.79
Interpretability: Medium (requires SHAP for better explanation)
Deployment Readiness: âš ï¸ Needs SHAP support

3.XGBoost
Accuracy: 86%
AUC: 0.82
Interpretability: Low (black-box model, hard to explain)
Deployment Readiness: âš ï¸ Needs SHAP

4.Hybrid Model (Logistic Regression + SHAP)
Accuracy: 80%
AUC: 0.75
Interpretability: âœ… Very High (best balance of explainability and performance)
Deployment Readiness: âœ… Easy